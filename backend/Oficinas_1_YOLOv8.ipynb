{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b81d14-9416-4e88-a518-94d238abbfa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.134 is required but found version=8.0.160, to fix: `pip install ultralytics==8.0.134`\n",
      "Downloading Dataset Version Zip in Metal-Film-Leaded-Resistor-Color-Bands-4 to yolov8: 26% [24600576 / 94310479] bytes"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Metal-Film-Leaded-Resistor-Color-Bands-4 to yolov8: 64% [60424192 / 94310479] bytes"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Metal-Film-Leaded-Resistor-Color-Bands-4 to yolov8: 100% [94310479 / 94310479] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to Metal-Film-Leaded-Resistor-Color-Bands-4 in yolov8:: 100%|█| 1402/1402 [00:00<00:00, \n"
     ]
    }
   ],
   "source": [
    "#!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"DwQSgWGYxeQmRJ29BCTy\")\n",
    "project = rf.workspace(\"uni-vug0c\").project(\"metal-film-leaded-resistor-color-bands\")\n",
    "dataset = project.version(4).download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddfc76c0-d7a0-4567-9c6c-f10c0aa012a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.171 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.160  Python-3.11.4 torch-2.0.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3060, 12287MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=segment, mode=train, model=yolov8n-seg.pt, data=Metal-Film-Leaded-Resistor-Color-Bands-4\\data.yaml, epochs=100, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\segment\\train4\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1004470  ultralytics.nn.modules.head.Segment          [2, 32, 64, [64, 128, 256]]   \n",
      "YOLOv8n-seg summary: 261 layers, 3264006 parameters, 3263990 gradients\n",
      "\n",
      "Transferred 381/417 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\segment\\train4', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Joule\\Documents\\Jhony\\Universidade\\UTFPR\\2023.2\\Oficinas\\Metal-Film-Leaded-Resistor-Color-Bands-4\\tr\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Joule\\Documents\\Jhony\\Universidade\\UTFPR\\2023.2\\Oficinas\\Metal-Film-Leaded-Resistor-\u001b[0m\n",
      "Plotting labels to runs\\segment\\train4\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 6 dataloader workers\n",
      "Logging results to \u001b[1mruns\\segment\\train4\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/100      3.08G      1.373      2.269      2.217      1.174          5        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.567      0.307       0.52       0.31      0.567      0.307      0.534      0.281\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/100      3.15G      1.205      1.617      1.664       1.01          0        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.707      0.551      0.618      0.363      0.707      0.551       0.63      0.333\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/100      2.99G      1.182      1.603      1.137      1.036          7        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.867      0.566      0.709      0.394      0.771      0.538      0.633      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/100      3.08G      1.194      1.604       1.13      1.047         10        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.762      0.724      0.792      0.465      0.731      0.699      0.741      0.403\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/100      3.02G      1.191      1.644      1.071      1.057         16        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.675      0.654      0.681      0.414      0.675      0.654      0.685      0.381\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/100         3G      1.178      1.553      1.031      1.053          4        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.905      0.751      0.886      0.519      0.907      0.748      0.873      0.473\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/100      3.15G      1.128      1.537      0.868      1.018          5        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.902      0.801      0.916      0.485       0.87      0.788      0.866      0.443\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/100      3.07G      1.116      1.542     0.8518      1.032          7        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172       0.92      0.833      0.914      0.528      0.894       0.81      0.864      0.443\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/100      3.06G      1.077      1.457     0.8045      1.018          7        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.799      0.839      0.887      0.571      0.784      0.822      0.867      0.502\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     10/100      2.98G      1.079      1.462     0.8002      1.025          7        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.967      0.788      0.901      0.516       0.94      0.766      0.846      0.454\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/100      3.06G     0.9854      1.399     0.8829     0.9702          0        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.862      0.875      0.923      0.575      0.892      0.834      0.919      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/100      3.02G      1.023       1.42     0.7226      1.006         12        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172       0.93      0.909      0.952      0.563      0.911       0.89      0.926      0.535\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/100      3.03G      1.005      1.414     0.7068          1          4        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.835      0.791      0.869       0.54      0.837       0.79      0.843      0.489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/100         3G      1.043      1.425     0.6791      1.014          5        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.936      0.924      0.944      0.561      0.942      0.929      0.948      0.537\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     15/100      3.05G     0.9843      1.374     0.6545     0.9954         13        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172       0.96      0.945      0.971      0.604      0.961      0.944       0.95      0.562\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     16/100      3.04G     0.9694      1.387     0.6306     0.9901          5        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.998      0.902       0.96      0.606      0.993      0.898      0.946      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     17/100      3.23G     0.9673      1.418     0.6294     0.9902          5        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.917      0.916      0.964      0.567      0.869      0.869      0.885      0.401\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     18/100      3.07G     0.9759      1.295     0.6256     0.9888          1        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.933      0.939      0.985      0.657      0.921      0.924      0.947      0.537\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     19/100      2.99G     0.8924      1.294     0.6591     0.9393          0        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.939      0.919      0.963      0.635      0.923      0.903      0.936      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     20/100       3.1G     0.9374      1.361      0.609     0.9844          4        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.965      0.827      0.937      0.621      0.982      0.839      0.944      0.553\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     21/100      3.05G     0.9476      1.318     0.6002     0.9864          7        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.957      0.917      0.975      0.583      0.958      0.901      0.955      0.554\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     22/100      2.98G     0.9023      1.318     0.5709     0.9734         11        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.959      0.917      0.953      0.645      0.975       0.94      0.953      0.573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     23/100       3.1G     0.9291      1.383     0.5856     0.9821          3        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.952      0.916      0.964       0.64      0.937      0.904      0.937      0.552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     24/100      2.97G     0.9038       1.33     0.5686     0.9696         11        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.907      0.903      0.944      0.655      0.887      0.883      0.919      0.571\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     25/100      3.14G     0.8655      1.298     0.5427     0.9669          6        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.898      0.988       0.96      0.601      0.876      0.867      0.866      0.466\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     26/100      3.01G     0.9222      1.318      0.567     0.9766          6        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.956      0.955      0.978      0.641       0.91       0.89      0.921      0.563\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     27/100      3.05G     0.8821      1.324     0.5306     0.9648          3        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.836      0.986      0.961      0.636      0.915      0.838      0.931      0.553\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     28/100      3.01G     0.8704      1.242     0.5373     0.9641         13        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.968      0.949      0.986      0.676      0.934      0.895      0.951      0.576\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     29/100      3.15G     0.8498      1.259      0.513     0.9588          7        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.937        0.9      0.952      0.642      0.955      0.916      0.961      0.575\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     30/100      3.01G     0.8586      1.217     0.5098     0.9602          5        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.936      0.914      0.969      0.651      0.929      0.907      0.963      0.579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     31/100      3.11G     0.8706      1.264     0.5134     0.9673          5        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.934      0.988      0.986      0.673      0.931      0.934      0.954      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     32/100      3.04G     0.8448      1.232      0.505     0.9546          9        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.945      0.951      0.983      0.688      0.945      0.951      0.948      0.595\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     33/100      3.14G     0.8469      1.183     0.5066     0.9547          5        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.964      0.963      0.981      0.663      0.937      0.976      0.979      0.588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     34/100      3.04G     0.8403      1.233     0.4887     0.9481          4        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.922       0.94      0.953      0.649      0.917      0.934      0.955      0.587\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     35/100      3.13G     0.8337      1.221     0.4852     0.9503         13        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.966      0.938       0.99      0.699      0.974      0.909      0.977      0.602\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     36/100      3.14G     0.8211      1.235     0.4704     0.9536         10        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.885      0.968      0.953      0.663      0.964      0.923      0.969      0.591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     37/100      3.06G     0.8077      1.206     0.4932     0.9195          0        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.927      0.956      0.969      0.678      0.938      0.952      0.978      0.594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     38/100      3.09G     0.8075       1.23     0.4732     0.9455          3        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.957      0.996      0.994      0.739      0.954      0.992      0.992      0.615\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     39/100      3.08G     0.7998      1.167     0.4758     0.9355          4        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.937       0.94      0.981      0.636      0.958      0.892      0.965       0.56\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     40/100      3.14G      0.811      1.169     0.4766     0.9432          8        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.888      0.971       0.97       0.67      0.967      0.905      0.975      0.586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     41/100      3.08G     0.8179      1.163     0.4605     0.9419          2        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.909      0.987      0.986      0.696      0.962      0.892      0.943      0.586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     42/100      2.98G     0.8014      1.212     0.4632     0.9382         12        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.951      0.985      0.994      0.684      0.967      0.935      0.981      0.604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     43/100      3.03G     0.7838      1.198     0.4476     0.9281          9        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.907      0.945      0.947      0.668      0.913       0.95      0.963      0.576\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     44/100      3.09G     0.7663      1.142     0.4496     0.9196          0        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172       0.98      0.951      0.992      0.695      0.972      0.944      0.968       0.57\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     45/100      3.03G     0.7643      1.156     0.4924     0.9084          0        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.922      0.993      0.991      0.702      0.933      0.947      0.973      0.599\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     46/100      3.03G     0.7595      1.136     0.4338     0.9245         10        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.904      0.976      0.972      0.681      0.898       0.96       0.95      0.585\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     47/100      3.03G     0.7963      1.116      0.451      0.929          4        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.938      0.951      0.974      0.676      0.896      0.918      0.948      0.566\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     48/100      3.13G     0.7519      1.112     0.4612     0.9368          1        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.955      0.956      0.955      0.648      0.897      0.956      0.967      0.553\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     49/100      3.03G     0.7724      1.163     0.4571     0.9392          1        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.968      0.998      0.992       0.69      0.916      0.984       0.98      0.596\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     50/100      3.09G     0.7971      1.192     0.4445      0.935          9        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.981      0.992      0.995      0.724      0.965      0.976      0.989       0.65\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     51/100      3.02G      0.767      1.126     0.4374     0.9283          4        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.944      0.959      0.982      0.678      0.937      0.951      0.983      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     52/100      3.12G     0.7671      1.161     0.4302     0.9299          2        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.982      0.996      0.993      0.698       0.94      0.956      0.958      0.599\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     53/100      3.03G     0.7711      1.128     0.4362     0.9373          5        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.933          1       0.99      0.695      0.899      0.963      0.965      0.582\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     54/100      3.18G     0.7826      1.101     0.4417     0.9241          3        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.969      0.985      0.994      0.705      0.941      0.962      0.977      0.608\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     55/100      3.14G     0.7578        1.1     0.4244     0.9135          3        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.937      0.993      0.991      0.691      0.899      0.956      0.965       0.58\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     56/100      3.05G     0.7303      1.109     0.4085     0.9266          5        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.948      0.963      0.977      0.717      0.932      0.947      0.974      0.592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     57/100      3.11G     0.7489      1.131     0.4183     0.9184          3        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.927          1      0.989      0.714        0.9      0.972      0.971      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     58/100      2.96G     0.7498      1.106     0.4236     0.9237          9        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.931      0.963      0.976      0.708      0.927       0.96      0.964      0.622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     59/100      3.17G     0.7165      1.092      0.397      0.915          5        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172       0.98      0.985      0.995      0.725      0.939      0.945      0.958       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     60/100      3.04G     0.7199      1.107     0.4075     0.9184          4        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172       0.97          1      0.994      0.695      0.946      0.976      0.983      0.587\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     61/100      3.03G     0.7204       1.11     0.4014     0.9188          9        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.985      0.972      0.994      0.691      0.927      0.972      0.973      0.587\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     62/100      2.97G     0.7468      1.097     0.4194     0.9171          3        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.972      0.996      0.992        0.7      0.944      0.968      0.971      0.604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     63/100      3.03G     0.7226       1.11     0.4047     0.9143          6        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.951          1      0.991      0.698      0.924      0.972       0.97      0.597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     64/100      3.14G      0.703       1.09     0.4224     0.8901          0        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.972          1      0.991       0.72       0.96      0.988      0.978       0.61\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     65/100      3.07G     0.7206      1.091     0.4027     0.9177          4        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.936      0.969      0.977      0.713      0.944      0.976      0.983      0.618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     66/100      3.02G     0.7151       1.16     0.4036     0.9221          7        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.965      0.998      0.992        0.7      0.949      0.982       0.98      0.585\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     67/100      3.07G      0.683      1.032     0.3809     0.9077         14        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.976          1      0.993      0.727      0.956       0.98      0.983      0.616\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     68/100      3.08G     0.6783      1.054     0.4096     0.8874          0        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.978      0.999      0.994       0.72      0.958      0.968      0.985      0.598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     69/100      2.95G     0.7233      1.055     0.3992     0.9103         13        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.975          1      0.993      0.719      0.957      0.981      0.979      0.596\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     70/100      3.11G     0.6667     0.9938     0.4049     0.8752          0        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.978          1      0.994      0.745      0.954      0.976      0.973      0.612\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     71/100      3.05G      0.675      1.014     0.4475     0.8791          0        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.939      0.976      0.976      0.713      0.924       0.96      0.966      0.579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     72/100      3.12G     0.7007      1.061     0.3919     0.9022         15        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.979      0.991      0.993      0.712      0.963      0.977      0.988      0.612\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     73/100      3.01G      0.674      1.005     0.3836     0.8997          5        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.954      0.976      0.972      0.701      0.973      0.984      0.991      0.605\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     74/100      3.06G      0.676      1.064     0.3858      0.908         17        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.927      0.963      0.975      0.716      0.922      0.996      0.988      0.615\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     75/100      2.99G     0.6751      1.007     0.3731     0.8987          5        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.964      0.974       0.99      0.734      0.944      0.955      0.974      0.589\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     76/100      2.98G     0.6537     0.9905     0.3744     0.8808          0        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.914      0.968       0.97      0.719       0.93      0.996      0.985      0.611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     77/100      3.07G     0.6661       1.02     0.3656     0.8955         14        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.975      0.986      0.994      0.751      0.952      0.996       0.99      0.613\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     78/100      3.06G      0.684      1.043     0.3766     0.8969         17        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.981      0.998      0.994      0.747      0.968      0.986      0.993      0.612\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     79/100      3.07G     0.6548     0.9878     0.3595     0.8942         13        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.942      0.966      0.982      0.724       0.93      0.955      0.954      0.592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     80/100      2.98G     0.6491     0.9858     0.4138     0.8755          0        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.981      0.973      0.993      0.721      0.952      0.944      0.968      0.608\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     81/100      3.06G      0.656      1.008     0.3565     0.8929         14        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.957      0.986      0.982      0.719      0.942       0.97       0.98      0.624\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     82/100      3.07G     0.6403     0.9943     0.3551     0.8883          4        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.973      0.988      0.986      0.704      0.958      0.972      0.985      0.602\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     83/100      2.98G     0.6741      1.004     0.3645     0.9079          4        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.944      0.976       0.98      0.729       0.94      0.972      0.985      0.629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     84/100      3.05G     0.6478      1.001     0.3581     0.8995          7        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.935      0.971      0.974      0.718       0.95      0.992      0.987      0.603\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     85/100         3G     0.6472      1.017     0.3597     0.8959          6        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.937      0.958      0.976      0.724      0.962      0.983      0.989      0.616\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     86/100      3.23G     0.6349     0.9699     0.3571     0.8935         13        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.964          1      0.992       0.74      0.961      0.996      0.988      0.622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     87/100       3.1G     0.6593     0.9937     0.3596     0.9021          8        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.976      0.977      0.994      0.746      0.929      0.984      0.983      0.622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     88/100      3.08G     0.6538     0.9711     0.3603      0.892          4        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.968          1      0.994      0.734       0.94      0.979      0.981      0.622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     89/100      3.05G     0.6286      1.008     0.3496     0.9002          4        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.967      0.959      0.987      0.725      0.984      0.975      0.993      0.626\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     90/100      3.01G     0.6109     0.9672     0.3389     0.8823          5        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.984      0.974      0.993      0.736       0.98      0.971      0.991      0.618\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     91/100      2.86G     0.5542     0.6674     0.3556     0.8576          1        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.968          1      0.993      0.725      0.952      0.984       0.99      0.594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     92/100      2.85G     0.5456      0.721     0.3059     0.8593          5        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.965          1      0.992      0.739      0.965          1      0.992      0.618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     93/100      2.88G     0.5323     0.6917      0.299     0.8518          5        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.941      0.972      0.974      0.741      0.968          1      0.994      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     94/100      2.84G     0.5424     0.7754     0.3098     0.8588          4        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.971      0.989      0.994      0.725      0.971      0.989      0.994      0.617\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     95/100      2.85G     0.5149     0.7008      0.299     0.8508          5        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.957      0.992      0.994       0.73      0.957      0.992      0.994      0.627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     96/100       2.8G     0.5314     0.7384     0.3001     0.8499          4        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.966          1      0.994      0.739      0.966          1      0.994      0.622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     97/100      2.85G     0.5188     0.6841     0.2905     0.8511          5        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.942      0.972      0.971      0.735      0.957      0.987      0.988      0.619\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     98/100       2.9G     0.5307     0.6998     0.2943     0.8608          5        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.944      0.956      0.972       0.72      0.951      0.965      0.986      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     99/100      2.87G     0.5041     0.6424     0.2867      0.832          0        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.973      0.993      0.994      0.744      0.969      0.989      0.992      0.637\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    100/100      2.87G     0.5453     0.7465     0.2945     0.8502          4        640: 100%|██████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.972      0.997      0.994      0.734      0.972      0.997      0.994      0.628\n",
      "\n",
      "100 epochs completed in 0.308 hours.\n",
      "Optimizer stripped from runs\\segment\\train4\\weights\\last.pt, 6.8MB\n",
      "Optimizer stripped from runs\\segment\\train4\\weights\\best.pt, 6.8MB\n",
      "\n",
      "Validating runs\\segment\\train4\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.160  Python-3.11.4 torch-2.0.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3060, 12287MiB)\n",
      "YOLOv8n-seg summary (fused): 195 layers, 3258454 parameters, 0 gradients\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P  \n",
      "                   all         56        172      0.973      0.993      0.994      0.744      0.969      0.989      0.992      0.635\n",
      "  Resistor-Color-Bands         56        131       0.97      0.998      0.994      0.798      0.963       0.99      0.989      0.621\n",
      "Resistor-Color-Bands-Start         56         41      0.976      0.988      0.995      0.689      0.976      0.988      0.995      0.649\n",
      "Speed: 0.5ms preprocess, 4.0ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\segment\\train4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install ultralytics\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "#model = YOLO('yolov8n-seg.yaml')  # build a new model from YAML\n",
    "#model = YOLO('D:\\\\Joule\\\\Documents\\\\Jhony\\\\Universidade\\\\UTFPR\\\\2023.2\\\\Oficinas\\\\runs\\\\segment\\\\train2\\\\weights\\\\best.pt')  # load a pretrained model (recommended for training)\n",
    "model = YOLO('yolov8n-seg.pt')  # build from YAML and transfer weights\n",
    "\n",
    "results = model.train(data=\"Metal-Film-Leaded-Resistor-Color-Bands-4\\\\data.yaml\", epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a5e7563-2fe8-4b9f-9fb8-74e7362f556b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency ultralytics==8.0.134 is required but found version=8.0.160, to fix: `pip install ultralytics==8.0.134`\n",
      "View the status of your deployment at: https://app.roboflow.com/uni-vug0c/metal-film-leaded-resistor-color-bands/4\n",
      "Share your model with the world at: https://universe.roboflow.com/uni-vug0c/metal-film-leaded-resistor-color-bands/model/4\n"
     ]
    }
   ],
   "source": [
    "version = project.version(4)\n",
    "version.deploy(\"yolov8\", \"D:\\\\Joule\\\\Documents\\\\Jhony\\\\Universidade\\\\UTFPR\\\\2023.2\\\\Oficinas\\\\runs\\\\segment\\\\train3\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db23b9ad-7dea-473b-8e28-5d30b0185d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def get_files(dir):\n",
    "    tests = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for name in files:\n",
    "            tests.append(os.path.join(dir,name))\n",
    "    return tests\n",
    "\n",
    "files = get_files(os.path.join(os.getcwd(), \"tmp\"))\n",
    "path_test = 'D:\\\\Joule\\\\Documents\\\\Jhony\\\\Universidade\\\\UTFPR\\\\2023.2\\\\Oficinas\\\\Tests\\\\01.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc5e5a06-9aba-42aa-bcc0-7ed09dac0499",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 Resistor-Color-Bandss, 202.1ms\n",
      "Speed: 4.5ms preprocess, 202.1ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\segment\\predict25\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pred = model([path_test], save=True, conf=0.6, show_labels=False, show_conf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c9cd52a-da71-435c-9841-c74d11c18d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 98.5ms\n",
      "Speed: 3.0ms preprocess, 98.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.2ms\n",
      "Speed: 2.0ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.9ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.5ms\n",
      "Speed: 2.0ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.5ms\n",
      "Speed: 1.0ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 2.5ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.5ms\n",
      "Speed: 2.0ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.5ms\n",
      "Speed: 2.0ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.5ms\n",
      "Speed: 2.0ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.5ms\n",
      "Speed: 2.0ms preprocess, 9.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.5ms\n",
      "Speed: 2.0ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.1ms\n",
      "Speed: 3.0ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.5ms\n",
      "Speed: 2.0ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.1ms\n",
      "Speed: 2.0ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.5ms\n",
      "Speed: 2.0ms preprocess, 7.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.1ms\n",
      "Speed: 1.0ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 3.5ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.4ms\n",
      "Speed: 2.0ms preprocess, 8.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.5ms\n",
      "Speed: 2.0ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.6ms\n",
      "Speed: 2.5ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.5ms\n",
      "Speed: 1.0ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.6ms\n",
      "Speed: 2.0ms preprocess, 8.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.3ms\n",
      "Speed: 2.0ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.5ms\n",
      "Speed: 1.0ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.5ms\n",
      "Speed: 1.9ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.6ms\n",
      "Speed: 2.0ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 17.4ms\n",
      "Speed: 2.0ms preprocess, 17.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 18.1ms\n",
      "Speed: 3.0ms preprocess, 18.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 5.5ms preprocess, 15.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.1ms\n",
      "Speed: 3.5ms preprocess, 16.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.5ms\n",
      "Speed: 2.5ms preprocess, 25.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.1ms\n",
      "Speed: 6.4ms preprocess, 25.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 20.5ms\n",
      "Speed: 3.0ms preprocess, 20.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 18.5ms\n",
      "Speed: 4.0ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 17.1ms\n",
      "Speed: 2.0ms preprocess, 17.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 17.5ms\n",
      "Speed: 1.6ms preprocess, 17.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 17.6ms\n",
      "Speed: 2.0ms preprocess, 17.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.5ms\n",
      "Speed: 2.0ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.5ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.5ms\n",
      "Speed: 1.6ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.5ms\n",
      "Speed: 2.0ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.5ms\n",
      "Speed: 2.5ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.5ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.1ms\n",
      "Speed: 2.0ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.5ms\n",
      "Speed: 2.0ms preprocess, 11.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 2.5ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.4ms\n",
      "Speed: 2.0ms preprocess, 8.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.5ms\n",
      "Speed: 2.0ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.8ms\n",
      "Speed: 2.5ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.5ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.4ms\n",
      "Speed: 1.0ms preprocess, 9.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.6ms\n",
      "Speed: 2.0ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.2ms\n",
      "Speed: 2.0ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.6ms\n",
      "Speed: 3.5ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.3ms\n",
      "Speed: 2.0ms preprocess, 9.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.6ms\n",
      "Speed: 3.0ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.1ms\n",
      "Speed: 2.0ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 23.6ms\n",
      "Speed: 3.0ms preprocess, 23.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 22.0ms\n",
      "Speed: 3.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 19.1ms\n",
      "Speed: 2.0ms preprocess, 19.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 21.1ms\n",
      "Speed: 2.0ms preprocess, 21.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 19.4ms\n",
      "Speed: 2.0ms preprocess, 19.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 21.0ms\n",
      "Speed: 2.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.6ms\n",
      "Speed: 2.0ms preprocess, 16.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.6ms\n",
      "Speed: 4.5ms preprocess, 16.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.1ms\n",
      "Speed: 2.0ms preprocess, 13.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.1ms\n",
      "Speed: 3.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.9ms\n",
      "Speed: 2.0ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.6ms\n",
      "Speed: 2.0ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.1ms\n",
      "Speed: 3.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.2ms\n",
      "Speed: 3.5ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.5ms\n",
      "Speed: 2.0ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.5ms\n",
      "Speed: 2.6ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.5ms\n",
      "Speed: 3.0ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.1ms\n",
      "Speed: 2.0ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.8ms\n",
      "Speed: 3.0ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.6ms\n",
      "Speed: 2.1ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.5ms\n",
      "Speed: 4.0ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.1ms\n",
      "Speed: 3.0ms preprocess, 15.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.5ms\n",
      "Speed: 5.6ms preprocess, 12.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.1ms\n",
      "Speed: 3.0ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.1ms\n",
      "Speed: 3.5ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.5ms\n",
      "Speed: 2.0ms preprocess, 12.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.2ms\n",
      "Speed: 3.0ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.2ms\n",
      "Speed: 3.0ms preprocess, 9.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.6ms\n",
      "Speed: 2.0ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.6ms\n",
      "Speed: 2.0ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.1ms\n",
      "Speed: 2.0ms preprocess, 14.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.5ms\n",
      "Speed: 2.5ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.5ms\n",
      "Speed: 2.0ms preprocess, 9.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.9ms\n",
      "Speed: 2.0ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.5ms\n",
      "Speed: 3.5ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.6ms\n",
      "Speed: 1.0ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.8ms\n",
      "Speed: 2.0ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.5ms\n",
      "Speed: 2.0ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.5ms\n",
      "Speed: 2.2ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.5ms\n",
      "Speed: 3.0ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.1ms\n",
      "Speed: 2.0ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.3ms\n",
      "Speed: 3.0ms preprocess, 14.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 2.5ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.5ms\n",
      "Speed: 2.0ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.5ms\n",
      "Speed: 2.0ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.5ms\n",
      "Speed: 2.0ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.5ms\n",
      "Speed: 3.0ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.5ms\n",
      "Speed: 2.0ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.5ms\n",
      "Speed: 2.0ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 2.5ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.5ms\n",
      "Speed: 2.0ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.9ms\n",
      "Speed: 3.0ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.6ms\n",
      "Speed: 1.5ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.5ms\n",
      "Speed: 3.0ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.4ms\n",
      "Speed: 2.0ms preprocess, 13.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.5ms\n",
      "Speed: 4.0ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.6ms\n",
      "Speed: 2.0ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.5ms\n",
      "Speed: 4.0ms preprocess, 13.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 2.5ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.8ms\n",
      "Speed: 2.0ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.1ms\n",
      "Speed: 2.5ms preprocess, 14.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.5ms\n",
      "Speed: 3.0ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.1ms\n",
      "Speed: 3.0ms preprocess, 12.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.6ms\n",
      "Speed: 2.5ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.5ms\n",
      "Speed: 4.1ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.6ms\n",
      "Speed: 6.0ms preprocess, 11.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.7ms\n",
      "Speed: 3.0ms preprocess, 12.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.5ms\n",
      "Speed: 2.4ms preprocess, 13.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.5ms\n",
      "Speed: 2.5ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.1ms\n",
      "Speed: 5.6ms preprocess, 13.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.1ms\n",
      "Speed: 3.0ms preprocess, 14.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.1ms\n",
      "Speed: 3.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.6ms\n",
      "Speed: 2.0ms preprocess, 16.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.5ms\n",
      "Speed: 4.6ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.6ms\n",
      "Speed: 4.0ms preprocess, 14.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.1ms\n",
      "Speed: 3.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.7ms\n",
      "Speed: 5.5ms preprocess, 12.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.1ms\n",
      "Speed: 3.0ms preprocess, 13.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.5ms\n",
      "Speed: 2.0ms preprocess, 13.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.1ms\n",
      "Speed: 3.0ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.7ms\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.7ms\n",
      "Speed: 2.0ms preprocess, 15.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.1ms\n",
      "Speed: 2.5ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.7ms\n",
      "Speed: 7.0ms preprocess, 35.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.1ms\n",
      "Speed: 2.5ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.6ms\n",
      "Speed: 2.0ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.6ms\n",
      "Speed: 3.4ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.1ms\n",
      "Speed: 2.5ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.3ms\n",
      "Speed: 2.5ms preprocess, 14.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.5ms\n",
      "Speed: 4.5ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.6ms\n",
      "Speed: 2.0ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.0ms\n",
      "Speed: 5.6ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.9ms\n",
      "Speed: 2.0ms preprocess, 13.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.5ms\n",
      "Speed: 5.0ms preprocess, 12.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.1ms\n",
      "Speed: 3.6ms preprocess, 11.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.3ms\n",
      "Speed: 3.0ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.6ms\n",
      "Speed: 3.0ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.6ms\n",
      "Speed: 4.5ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.6ms\n",
      "Speed: 4.0ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.6ms\n",
      "Speed: 2.0ms preprocess, 12.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 1.9ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.6ms\n",
      "Speed: 2.0ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.5ms\n",
      "Speed: 4.2ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.1ms\n",
      "Speed: 2.0ms preprocess, 11.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.6ms\n",
      "Speed: 1.5ms preprocess, 11.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.1ms\n",
      "Speed: 2.0ms preprocess, 14.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.6ms\n",
      "Speed: 2.0ms preprocess, 13.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.5ms\n",
      "Speed: 3.0ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.3ms\n",
      "Speed: 2.5ms preprocess, 14.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.3ms\n",
      "Speed: 3.6ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.1ms\n",
      "Speed: 1.6ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.8ms\n",
      "Speed: 2.0ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.2ms\n",
      "Speed: 2.5ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.6ms\n",
      "Speed: 2.0ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.6ms\n",
      "Speed: 2.0ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.1ms\n",
      "Speed: 3.0ms preprocess, 14.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.6ms\n",
      "Speed: 2.0ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.5ms\n",
      "Speed: 2.6ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.7ms\n",
      "Speed: 2.0ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.1ms\n",
      "Speed: 3.0ms preprocess, 14.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.3ms\n",
      "Speed: 3.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.9ms\n",
      "Speed: 2.0ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 17.7ms\n",
      "Speed: 4.0ms preprocess, 17.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.0ms\n",
      "Speed: 1.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.5ms\n",
      "Speed: 2.6ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.9ms\n",
      "Speed: 2.6ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.4ms\n",
      "Speed: 3.0ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.6ms\n",
      "Speed: 1.5ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.4ms\n",
      "Speed: 5.6ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.7ms\n",
      "Speed: 3.0ms preprocess, 14.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.2ms\n",
      "Speed: 3.0ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.5ms\n",
      "Speed: 3.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.5ms\n",
      "Speed: 4.6ms preprocess, 12.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.6ms\n",
      "Speed: 2.6ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.6ms\n",
      "Speed: 2.0ms preprocess, 16.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.5ms\n",
      "Speed: 3.1ms preprocess, 12.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.1ms\n",
      "Speed: 4.0ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.0ms\n",
      "Speed: 6.5ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.1ms\n",
      "Speed: 6.0ms preprocess, 34.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.5ms\n",
      "Speed: 4.6ms preprocess, 11.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.6ms\n",
      "Speed: 2.0ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.5ms\n",
      "Speed: 6.0ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.3ms\n",
      "Speed: 2.0ms preprocess, 14.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.6ms\n",
      "Speed: 2.0ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 2.5ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.5ms\n",
      "Speed: 2.6ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.1ms\n",
      "Speed: 3.0ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.6ms\n",
      "Speed: 2.6ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.6ms\n",
      "Speed: 3.5ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.1ms\n",
      "Speed: 4.0ms preprocess, 12.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.4ms\n",
      "Speed: 2.0ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.1ms\n",
      "Speed: 2.0ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.6ms\n",
      "Speed: 3.0ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.6ms\n",
      "Speed: 4.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.5ms\n",
      "Speed: 2.0ms preprocess, 14.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.5ms\n",
      "Speed: 2.0ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.6ms\n",
      "Speed: 1.5ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.7ms\n",
      "Speed: 2.0ms preprocess, 14.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.6ms\n",
      "Speed: 2.0ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.6ms\n",
      "Speed: 3.0ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.6ms\n",
      "Speed: 1.5ms preprocess, 11.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.6ms\n",
      "Speed: 2.5ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.5ms\n",
      "Speed: 2.0ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.6ms\n",
      "Speed: 2.0ms preprocess, 14.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.5ms\n",
      "Speed: 2.0ms preprocess, 12.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.5ms\n",
      "Speed: 2.6ms preprocess, 13.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.5ms\n",
      "Speed: 2.6ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.6ms\n",
      "Speed: 1.0ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.6ms\n",
      "Speed: 1.5ms preprocess, 14.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.5ms\n",
      "Speed: 2.0ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.4ms\n",
      "Speed: 5.0ms preprocess, 16.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.5ms\n",
      "Speed: 2.0ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.5ms\n",
      "Speed: 2.5ms preprocess, 16.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.5ms\n",
      "Speed: 3.0ms preprocess, 14.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.5ms\n",
      "Speed: 3.0ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.6ms\n",
      "Speed: 3.0ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.4ms\n",
      "Speed: 4.0ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.6ms\n",
      "Speed: 1.5ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.6ms\n",
      "Speed: 2.0ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.7ms\n",
      "Speed: 2.0ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.6ms\n",
      "Speed: 2.2ms preprocess, 16.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.7ms\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.1ms\n",
      "Speed: 2.5ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.5ms\n",
      "Speed: 4.0ms preprocess, 12.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.7ms\n",
      "Speed: 2.5ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.7ms\n",
      "Speed: 4.2ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.1ms\n",
      "Speed: 6.6ms preprocess, 35.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.2ms\n",
      "Speed: 5.0ms preprocess, 37.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.5ms\n",
      "Speed: 3.0ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 2.1ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.6ms\n",
      "Speed: 2.0ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.5ms\n",
      "Speed: 2.0ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 5.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.5ms\n",
      "Speed: 2.0ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.5ms\n",
      "Speed: 3.0ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "\n",
    "for file in files:\n",
    "    npath = \"\\\\\".join(file.split(\"\\\\\")[:-2])  # Gets root dir\n",
    "    npath = os.path.join(npath, \"Resistores_Cropped\\\\\"+file.split(\"\\\\\")[-1])\n",
    "    if not os.path.isfile(npath):\n",
    "        try:\n",
    "            pred = model([file])\n",
    "            img = cv.imread(file)\n",
    "            box = [int(i) for i in pred[0].boxes.data[0]]\n",
    "            img = img[box[1]:box[3], box[0]:box[2]]\n",
    "            Image.fromarray(cv.cvtColor(img, cv.COLOR_BGR2RGB)).save(npath)\n",
    "        except IndexError:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b300698-9668-478e-b035-0241f93ff819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d74163b-48b5-4b22-8811-b00bf25955ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def vect_angle(color1, color2):\n",
    "    dp = np.dot(color1, color2)/(norm(color1)*norm(color2))\n",
    "    if dp > 1:\n",
    "        dp = 1.0\n",
    "    elif dp < -1:\n",
    "        dp = -1.0\n",
    "    return np.arccos(dp)  # in radians\n",
    "\n",
    "def get_neighbours(imarr, r, c, kernel_size=3):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    neighbours = list()\n",
    "    k_s = kernel_size//2\n",
    "    for i in range(r-k_s, r+k_s+1):\n",
    "        for j in range(c-k_s, c+k_s+1):\n",
    "            if i >= 0 and i < len(imarr) and j >= 0 and j < len(imarr[i]):\n",
    "                if (r, c) != (i, j):\n",
    "                    neighbours.append(imarr[i][j])\n",
    "    return neighbours\n",
    "\n",
    "def filter_neighbours(pixel, neighbours, angle_thresh, dist_thresh):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    valid = list()\n",
    "    for neighbour in neighbours:\n",
    "        if get_angle(pixel, neighbour) < angle_thresh and (get_module(pixel) - get_module(neighbour)) < dist_thresh:\n",
    "            valid.append(neighbour)\n",
    "    return valid\n",
    "\n",
    "def scalar_prod(vector, scalar): \n",
    "    return [i*scalar for i in vector]\n",
    "\n",
    "def vector_sum(v1, v2):\n",
    "    return [a+b for a,b in zip(v1, v2)]\n",
    "\n",
    "def sum_vectors(lv):\n",
    "    if len(lv) == 1:\n",
    "        return lv[0]\n",
    "    elif len(lv) == 0:\n",
    "        raise IndexError\n",
    "    rs = vector_sum(lv[0], lv[1])\n",
    "    for i in lv[2:]:\n",
    "        rs = vector_sum(rs, i)\n",
    "    return rs\n",
    "\n",
    "def color_selective_blur(imarr, retention_rate, thresh=5):\n",
    "    \"\"\"\n",
    "    Acts like a gaussian blur (center of Kernel is equal to retention_rate here), but only takes\n",
    "    into consideration the pixels that are thresh away in modulus (normalized vector distances)\n",
    "    INPUTS\n",
    "        imarr: 2D array\n",
    "        retention_rate: 0.0-1.0\n",
    "    \"\"\"\n",
    "    for row in range(len(imarr)):\n",
    "        for column in range(len(imarr[row])):\n",
    "            neighbours = get_neighbours(imarr, row, column)\n",
    "            neighbours = filter_neighbours(imarr[row][column], neighbours, 3.1415926535/24, 100)\n",
    "            if len(neighbours):\n",
    "                weight = (1-retention_rate)/len(neighbours)\n",
    "            else:\n",
    "                neighbours = get_neighbours(imarr, row, column)\n",
    "                weight = (1-retention_rate)/len(neighbours)\n",
    "            neighbours = [scalar_prod(i, weight) for i in neighbours]\n",
    "            somm = sum_vectors(neighbours)\n",
    "            imarr[row][column] = vector_sum(scalar_prod(imarr[row][column], retention_rate), somm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6040772a-8d56-4662-9010-a4959313aa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "Colour_Range = [\n",
    "    [(0, 0, 0), (255, 255, 20), \"BLACK\", 0, (0, 0, 0)],\n",
    "    [(0, 90, 10), (15, 250, 100), \"BROWN\", 1, (0, 51, 102)],\n",
    "    [(0, 30, 80), (10, 255, 200), \"RED\", 2, (0, 0, 255)],\n",
    "    [(5, 150, 150), (15, 235, 250), \"ORANGE\", 3, (0, 128, 255)],  # ok\n",
    "    [(50, 100, 100), (70, 255, 255), \"YELLOW\", 4, (0, 255, 255)],\n",
    "    [(45, 100, 50), (75, 255, 255), \"GREEN\", 5, (0, 255, 0)],  # ok\n",
    "    [(100, 150, 0), (140, 255, 255), \"BLUE\", 6, (255, 0, 0)],  # ok\n",
    "    [(120, 40, 100), (140, 250, 220), \"VIOLET\", 7, (255, 0, 127)],\n",
    "    [(0, 0, 50), (179, 50, 80), \"GRAY\", 8, (128, 128, 128)],\n",
    "    [(0, 0, 90), (179, 15, 250), \"WHITE\", 9, (255, 255, 255)],\n",
    "]\n",
    "\n",
    "# Bilateral filter and resize the image\n",
    "img = cv.imread('Tests\\\\resistor_iluminado_crop.png')\n",
    "def bilateral_filter(img):\n",
    "    D, I = 4, 150\n",
    "    scale = 8\n",
    "    \n",
    "    fimg = cv.bilateralFilter(img, D, I, I)\n",
    "    width = fimg.shape[1]*scale\n",
    "    height = fimg.shape[0]*scale\n",
    "    fimg = cv.resize(fimg, (width, height))\n",
    "    return fimg\n",
    "\n",
    "#Image.fromarray(cv.cvtColor(fimg, cv.COLOR_RGB2BGR)).save(f\"Tests\\\\bilateral_filter_2_D{D}_I{I}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55d50522-6172-4fae-8e15-bd8a91644f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhony\\AppData\\Local\\Temp\\ipykernel_1368\\1071019581.py:24: RuntimeWarning: overflow encountered in scalar subtract\n",
      "  H = 4 + 60*(color[2] - color[1])/(M - m)\n",
      "C:\\Users\\jhony\\AppData\\Local\\Temp\\ipykernel_1368\\1071019581.py:30: RuntimeWarning: overflow encountered in scalar subtract\n",
      "  H = 60*(color[1] - color[0])/(M - m)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\npath = \"D:\\\\Joule\\\\Documents\\\\Jhony\\\\Universidade\\\\UTFPR\\\\2023.2\\\\Oficinas\\\\Tests\\\\resistor_iluminado_crop.png\"\\nimg = cv.imread(path)\\nimg = bilateral_filter(img)\\ngroups = find_color_pools(img)\\nimgcp = deepcopy(img)\\nsizes = [len(i.coords) for i in groups.objects]\\nsizes.sort(reverse=True)\\nfor obj in groups.objects:\\n    for size in sizes[:2]:\\n        if len(obj.coords) < size:\\n            c = Contour(obj.coords)\\n            print(c.get_boundaries())\\n#\\n#Image.fromarray(cv.cvtColor(imgcp, cv.COLOR_HSV2RGB)).save(os.path.join(os.getcwd(), f\"{\\'.\\'.join(file.split(\\'.\\')[:-1])}_colorized.png\"))\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def dot_product(v1, v2):\n",
    "    return sum(int(a)*int(b) for a,b in zip(v1, v2))\n",
    "\n",
    "def vect_angle(color1, color2):\n",
    "    dp = dot_product(color1, color2)/(norm(color1)*norm(color2))\n",
    "    if dp > 1:\n",
    "        dp = 1.0\n",
    "    elif dp < -1:\n",
    "        dp = -1.0\n",
    "    return np.arccos(dp)  # in radians\n",
    "\n",
    "def bilateral_filter(img):\n",
    "    D, I = 4, 150\n",
    "    target_width = 100\n",
    "    scale = target_width/img.shape[1]\n",
    "    #\n",
    "    fimg = cv.bilateralFilter(img, D, I, I)\n",
    "    width = fimg.shape[1]*scale\n",
    "    height = fimg.shape[0]*scale\n",
    "    fimg = cv.resize(fimg, (int(width), int(height)))\n",
    "    return fimg\n",
    "\n",
    "class Contour:\n",
    "    def __init__(self, points=[]):\n",
    "        self.points = list(points)\n",
    "    # Adds data and/or updates Contour boundaries\n",
    "    def update(self, points=[]):\n",
    "        self.points.append(i for i in points)\n",
    "    # Calculates and returns the sub-boundaries in self.points\n",
    "    def get_boundaries(self):\n",
    "        # Returns neighbors to a point dist-pixels away\n",
    "        def get_neighbors(point, dist=3):\n",
    "            n = list()\n",
    "            for i in range(-(dist//2),1+dist//2):\n",
    "                for j in range(-(dist//2),1+dist//2):\n",
    "                    n.append(list(np.add(point, (i,j))))\n",
    "            return n\n",
    "        #\n",
    "        def in_boundary(point, boundary):\n",
    "            if point >= boundary[0] and point < boundary[1]:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        # Iteratively finds sub-boundaries\n",
    "        subb = []\n",
    "        points = deepcopy(self.points)\n",
    "        for point in self.points:\n",
    "            contained = False\n",
    "            index = -1\n",
    "            for i in range(len(subb)):\n",
    "                if not contained and in_boundary(point, subb[i]):\n",
    "                    contained = True\n",
    "                    index = i\n",
    "                    break\n",
    "            if not contained:\n",
    "                subb.append([point, point])\n",
    "            #\n",
    "            neighbors = [n for n in get_neighbors(point) if (list(n) in self.points or tuple(n) in self.points)]\n",
    "            # Updates boundary with top-left-most and bottom-right-most points in its proximity\n",
    "            subb[index][0] = min(list(min(neighbors)), list(subb[index][0]))\n",
    "            subb[index][1] = max(list(max(neighbors)), list(subb[index][1]))\n",
    "        return subb            \n",
    "    # Returns the index-th boundary\n",
    "    def __getitem__(self, index):\n",
    "        return self.points[index]\n",
    "\n",
    "\n",
    "class Color:\n",
    "    def __init__(self, image, pos, thresh = 255, angle_thresh = np.pi*15/180):\n",
    "        self.image = image\n",
    "        self.color = image[pos[0]][pos[1]]\n",
    "        self.coords = [pos]  # List of the coordinates of the pixels that have the 'same' color\n",
    "        self.thresh = thresh\n",
    "        self.angle_thresh = angle_thresh\n",
    "    # Overloads the equality operator (==)\n",
    "    def __eq__(self, pos):\n",
    "        c = self.image[pos[0]][pos[1]]\n",
    "        if abs(norm(self.color) - norm(c)) <= self.thresh and vect_angle(self.color, c) < self.angle_thresh:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    # Overloads the contains operator (in)\n",
    "    def __contains__(self, pos):\n",
    "        return self.__eq__(pos)\n",
    "    # Adds a color to the group\n",
    "    def append(self, pos):\n",
    "        if pos not in self.coords:\n",
    "            self.coords.append(pos)\n",
    "        R,G,B = 0,0,0\n",
    "        for x,y in self.coords:\n",
    "            R += self.image[x][y][0]\n",
    "            G += self.image[x][y][1]\n",
    "            B += self.image[x][y][2]\n",
    "        R /= len(self.coords)\n",
    "        G /= len(self.coords)\n",
    "        B /= len(self.coords)\n",
    "        self.color = [R,G,B]\n",
    "\n",
    "class Group:\n",
    "    def __init__(self, objs = []):\n",
    "        self.objects = objs\n",
    "    # Adds an object to the group\n",
    "    def insert(self, obj):\n",
    "        self.objects.append(obj)\n",
    "    # Checks if an element is in any of its subgroups\n",
    "    def __contains__(self, elem):\n",
    "        for obj in self.objects:\n",
    "            if elem in obj:\n",
    "                return True\n",
    "        return False\n",
    "    # Adds an element to one of its subgroups\n",
    "    def append(self, elem):\n",
    "        for obj in self.objects:\n",
    "            if elem in obj:\n",
    "                obj.append(elem)\n",
    "                return\n",
    "\n",
    "def find_color_pools(im, color_space=cv.COLOR_BGR2HSV):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    img = cv.cvtColor(im, color_space)\n",
    "    groups = Group()\n",
    "    for i in range(len(img)):\n",
    "        for j in range(len(img[i])):\n",
    "            if (i,j) not in groups:\n",
    "                cg = Color(img, (i,j))\n",
    "                groups.insert(cg)\n",
    "            else:\n",
    "                groups.append([i,j])\n",
    "    return groups\n",
    "\n",
    "# Paints similar colors the same\n",
    "\"\"\"for file in get_files(os.path.join(os.getcwd(), \"Tests\\\\light\")):\n",
    "    img = cv.imread(file)\n",
    "    img = bilateral_filter(img)\n",
    "    groups = find_color_pools(img)\n",
    "    imgcp = deepcopy(img)\n",
    "    for obj in groups.objects:\n",
    "        for point in obj.coords:\n",
    "            imgcp[point[0]][point[1]] = obj.color\n",
    "    #\n",
    "    Image.fromarray(cv.cvtColor(imgcp, cv.COLOR_HSV2RGB)).save(os.path.join(os.getcwd(), f\"{'.'.join(file.split('.')[:-1])}_colorized.png\"))\n",
    "\"\"\"\n",
    "file = \"Tests\\\\resistor_iluminado_crop.png\"\n",
    "img = cv.imread(file)\n",
    "img = bilateral_filter(img)\n",
    "groups = find_color_pools(img)\n",
    "imgcp = deepcopy(img)\n",
    "for obj in groups.objects:\n",
    "    for point in obj.coords:\n",
    "        imgcp[point[0]][point[1]] = obj.color\n",
    "#\n",
    "Image.fromarray(cv.cvtColor(imgcp, cv.COLOR_HSV2RGB)).save(os.path.join(os.getcwd(), f\"{'.'.join(file.split('.')[:-1])}_colorized.png\"))\n",
    "\"\"\"\n",
    "path = \"D:\\\\Joule\\\\Documents\\\\Jhony\\\\Universidade\\\\UTFPR\\\\2023.2\\\\Oficinas\\\\Tests\\\\resistor_iluminado_crop.png\"\n",
    "img = cv.imread(path)\n",
    "img = bilateral_filter(img)\n",
    "groups = find_color_pools(img)\n",
    "imgcp = deepcopy(img)\n",
    "sizes = [len(i.coords) for i in groups.objects]\n",
    "sizes.sort(reverse=True)\n",
    "for obj in groups.objects:\n",
    "    for size in sizes[:2]:\n",
    "        if len(obj.coords) < size:\n",
    "            c = Contour(obj.coords)\n",
    "            print(c.get_boundaries())\n",
    "#\n",
    "#Image.fromarray(cv.cvtColor(imgcp, cv.COLOR_HSV2RGB)).save(os.path.join(os.getcwd(), f\"{'.'.join(file.split('.')[:-1])}_colorized.png\"))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "822f3c5e-f7d8-4488-9650-e36423736734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1021"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(groups.objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be962ea7-8d31-4648-83bc-418494444ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
